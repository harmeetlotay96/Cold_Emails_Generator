{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcac5d5-1286-4be9-ba90-3babb68c242d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n1. Search for an open opportunity at your possible potential clients\\n2. Search for relevant information from the opening that might act as a good starting point for your business\\n3. Go through all of your company's projects and find relevant projects\\n4. Get important to share information about these projects\\n5. Write a compelling cold email about how your firm can be of great service to your potential client\\n6. Repeat for ALL potential clients\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Search for an open opportunity at your possible potential clients\n",
    "2. Search for relevant information from the opening that might act as a good starting point for your business\n",
    "3. Go through all of your company's projects and find relevant projects\n",
    "4. Get important to share information about these projects\n",
    "5. Write a compelling cold email about how your firm can be of great service to your potential client\n",
    "6. Repeat for ALL potential clients\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ea496a5-dac6-4ba8-a153-7a55a22db414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web Scraping\n",
    "\n",
    "# Relevant Information\n",
    "\n",
    "# Chromadb query\n",
    "\n",
    "# Email Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f61dd01-4d19-4329-ba79-38fd6cb64175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLoading .env environment variables...\u001b[0m\n",
      "\u001b[1;32mInstalling langchain_community...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(5bd434)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1;32mUpgrading\u001b[0m langchain_community in \u001b[39m dependencies.\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠙\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(385d37)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(385d37)...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Web Scraping\n",
    "!pipenv install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d252d4e1-7ab7-4db4-b1ab-d46e713738ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.capitalonecareers.com/job/plano/principal-associate-data-science-financial-services/1732/75657249248\")\n",
    "page_data = loader.load().pop().page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a807c718-98eb-4c98-88d2-222fb4f3d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "# response = llm.invoke(\"Who is the greatest footballer of all time?\")\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2de21e7-b23f-4509-a8c1-8e0b19c8d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I will give you a scraped text from a job posting.\n",
    "    Your job is to extract the job details & requirements in a JSON format containing the following keys: 'role', 'experience', 'skills' and 'description'.\n",
    "    Only return valid JSON. No preamble, please.\n",
    "    Here is the scraped text: {page_data}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c37778c8-67cc-4056-a9a2-c21035ce02ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"role\": \"Principal Associate, Data Science - Financial Services\",\n",
      "    \"experience\": \"Bachelor's Degree plus 5 years of experience in data analytics, or Master's Degree plus 3 years in data analytics, or PhD\",\n",
      "    \"skills\": [\n",
      "        \"Python\",\n",
      "        \"GitHub\",\n",
      "        \"Sagemaker\",\n",
      "        \"SQL\",\n",
      "        \"AWS\",\n",
      "        \"Machine learning\",\n",
      "        \"Open-source languages\",\n",
      "        \"Cloud computing platforms\",\n",
      "        \"Information Retrieval\",\n",
      "        \"Recommender System\",\n",
      "        \"Search Ranking\",\n",
      "        \"Large-scale, Real-time machine learning systems\"\n",
      "    ],\n",
      "    \"description\": \"Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love. Leverage a broad stack of technologies to reveal the insights hidden within huge volumes of numeric and textual data. Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation.\"\n",
      "}\n",
      "```\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "chain_extract = prompt_extract | llm\n",
    "response = chain_extract.invoke(input={'page_data': page_data})\n",
    "print(response.content)\n",
    "print(type(response.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6af6a45a-ff72-4fb2-ad85-47e204cbe26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'Principal Associate, Data Science - Financial Services', 'experience': \"Bachelor's Degree plus 5 years of experience in data analytics, or Master's Degree plus 3 years in data analytics, or PhD\", 'skills': ['Python', 'GitHub', 'Sagemaker', 'SQL', 'AWS', 'Machine learning', 'Open-source languages', 'Cloud computing platforms', 'Information Retrieval', 'Recommender System', 'Search Ranking', 'Large-scale, Real-time machine learning systems'], 'description': 'Partner with a cross-functional team of data scientists, software engineers, and product managers to deliver a product customers love. Leverage a broad stack of technologies to reveal the insights hidden within huge volumes of numeric and textual data. Build machine learning models through all phases of development, from design through training, evaluation, validation, and implementation.'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_response = json_parser.parse(response.content)\n",
    "\n",
    "print(json_response)\n",
    "print(type(json_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecbb4b00-324b-4222-b2ec-3ec2fab9b83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Python', ' SQL', ' Pandas')  https://github.com/user/project1\n",
      "('SQL', ' Python', ' Airflow')  https://github.com/user/project2\n",
      "('PySpark', ' Spark SQL', ' Delta Lake')  https://github.com/user/project3\n",
      "('Machine Learning', ' Deep Learning', ' TensorFlow')  https://github.com/user/project4\n",
      "('Data Engineering', ' ETL', ' ELT')  https://github.com/user/project5\n",
      "('Cloud Platforms (AWS', ' GCP', ' Azure)')  https://github.com/user/project6\n",
      "('Data Warehousing', ' Data Modeling', ' DBT')  https://github.com/user/project7\n",
      "('Data Visualization', ' Power BI', ' Tableau')  https://github.com/user/project8\n",
      "('MLOps', ' MLflow', ' Kubeflow')  https://github.com/user/project9\n",
      "('Natural Language Processing (NLP)', ' NLTK', ' spaCy')  https://github.com/user/project10\n",
      "('Computer Vision', ' OpenCV', ' TensorFlow')  https://github.com/user/project11\n",
      "('Time Series Analysis', ' Forecasting', ' Prophet')  https://github.com/user/project12\n",
      "('Data Cleaning', ' Data Wrangling', ' Pandas')  https://github.com/user/project13\n",
      "('Feature Engineering', ' Scikit-learn')  https://github.com/user/project14\n",
      "('Statistical Analysis', ' Hypothesis Testing')  https://github.com/user/project15\n",
      "('Data Ethics', ' Privacy', ' GDPR')  https://github.com/user/project16\n",
      "('Big Data', ' Hadoop', ' Spark')  https://github.com/user/project17\n",
      "('Data Governance', ' Data Quality', ' Metadata Management')  https://github.com/user/project18\n",
      "('Data Security', ' Encryption', ' Tokenization')  https://github.com/user/project19\n",
      "('Cloud Data Engineering', ' AWS Glue', ' Databricks')  https://github.com/user/project20\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        # Skip the header row\n",
    "        next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            # Separate technical skills (list) and project link (string)\n",
    "            skills = tuple(row[:-1]) # Exclude the last element which is the project link\n",
    "            project_link = row[-1] \n",
    "            data.append((skills, project_link))\n",
    "    return data\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'sample_portfolio.csv'\n",
    "data = read_csv_file(file_path)\n",
    "\n",
    "for skills, project_link in data:\n",
    "    print(skills, project_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00c14958-ffe6-4599-9b79-742260878177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into vector database\n",
    "\n",
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name='portfolio_links')\n",
    "\n",
    "if not collection.count():\n",
    "    for skills, project_link in data:\n",
    "        collection.add(\n",
    "            documents=str(skills),\n",
    "            metadatas={\n",
    "                'portfolio_url': project_link\n",
    "            },\n",
    "            ids = str(uuid.uuid4())\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d79bc439-f7d5-46a1-899d-a76b98922315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'GitHub',\n",
       " 'Sagemaker',\n",
       " 'SQL',\n",
       " 'AWS',\n",
       " 'Machine learning',\n",
       " 'Open-source languages',\n",
       " 'Cloud computing platforms',\n",
       " 'Information Retrieval',\n",
       " 'Recommender System',\n",
       " 'Search Ranking',\n",
       " 'Large-scale, Real-time machine learning systems']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ff90123-8176-4aeb-8cbc-3ec8b7951ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['72e6ed32-3af0-475e-9d1a-5caab35badff',\n",
       "   '4d17ad99-d9ee-45f3-b544-377a4a5c8b3d']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"('SQL', ' Python', ' Airflow')\",\n",
       "   \"('Python', ' SQL', ' Pandas')\"]],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'portfolio_url': ' https://github.com/user/project2'},\n",
       "   {'portfolio_url': ' https://github.com/user/project1'}]],\n",
       " 'distances': [[1.0100101142910578, 1.0451927628216906]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_portfolio_urls = collection.query(query_texts=json_response['skills'][0], n_results=2)\n",
    "matched_portfolio_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dfbe8a6-a70e-4fff-9dc3-77d3a2b835ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    I will give you a role and a task that you have to perform in that specific role.\n",
    "    Your Role: Your name is Harmeet, You are an incredible business development officer who knows how to get clients. You work for X Consulting firm, your firm works with all sorts of IT clients and provide solutions in the domain of Data Science and AI. \n",
    "    X AI focuses on efficient tailored solutions for all clients keeping costs down. \n",
    "    Your Job: Your Job is to write cold emails to clients regarding the Job openings that they have advertised. Try to pitch your clients with an email hook that opens a conversation about a possibility of working with them. Add the most relevant portfolio URLs from\n",
    "    the following (shared below) to showcase that we have the right expertise to get the job done. \n",
    "    I will now provide you with the Job description and the portfolio URLs:\n",
    "    JOB DESCRIPTION: {job_description}\n",
    "    ------\n",
    "    PORTFOLIO URLS: {portfolio_urls}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99cc0286-4b0e-4c59-805c-3a6675d47b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = json_response['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae0e0f3c-7dc3-4ba9-8bfe-959e58eaab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Unlocking Hidden Insights with X AI's Expertise in Data Science and AI\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I came across your job posting for a data scientist position, and I was impressed by the opportunity to work with a cross-functional team to deliver a product that customers love. As a Business Development Officer at X Consulting firm, I'd like to introduce you to our team of experts in Data Science and AI, who have a proven track record of leveraging a broad stack of technologies to reveal insights hidden within large volumes of data.\n",
      "\n",
      "Our team has extensive experience in building machine learning models, from design through training, evaluation, validation, and implementation. We've worked with a range of technologies, including SQL, Python, Airflow, and Pandas, to name a few. I'd like to highlight a couple of our notable projects that demonstrate our expertise:\n",
      "\n",
      "* https://github.com/user/project1: This project showcases our ability to work with large datasets, applying machine learning algorithms to extract valuable insights.\n",
      "* https://github.com/user/project2: This project demonstrates our expertise in building scalable data pipelines using Airflow and Python, ensuring efficient data processing and analysis.\n",
      "\n",
      "At X AI, we focus on providing efficient, tailored solutions that keep costs down without compromising on quality. Our team is passionate about delivering exceptional results, and we're excited about the possibility of collaborating with your team to drive business growth.\n",
      "\n",
      "I'd love to schedule a call to discuss how our expertise can support your project goals. Please let me know if you're open to exploring this opportunity further.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Harmeet\n",
      "Business Development Officer\n",
      "X Consulting firm\n",
      "X AI\n"
     ]
    }
   ],
   "source": [
    "chain_email = email_prompt | llm\n",
    "response = chain_email.invoke({'job_description':job_description, 'portfolio_urls':matched_portfolio_urls})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df4dfe-7756-46c2-bdf9-77e51f09832f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
